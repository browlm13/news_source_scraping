{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = ['aa aa bb cc.',\n",
    "        'cc dd ee ff.',\n",
    "        'ff ff gg aa']\n",
    "\n",
    "corpus = '\\n\\n'.join(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Build Co-occurence Matrix, A\n",
    "#\n",
    "\n",
    "import itertools\n",
    "\n",
    "# external\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.util import ngrams\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "def process_text(text):\n",
    "\t\"\"\" return list of lowercase alphabetic words from text \"\"\"\n",
    "\ttokenizer = RegexpTokenizer(r'\\w+')\n",
    "\treturn tokenizer.tokenize(text.lower())\n",
    "\n",
    "def ngram_tupples(corpus, n):\n",
    "\t\"\"\" Create ngram tupples by sentence. Where n is the distance between words in a sentence. \"\"\"\n",
    "\tsentences = sent_tokenize(corpus)\n",
    "\n",
    "\tpairs = []\n",
    "\tfor s in sentences:\n",
    "\t\tunique_tokens = process_text(s)\n",
    "\t\tpairs.extend(ngrams(unique_tokens,n))\n",
    "\n",
    "\treturn pairs\n",
    "\n",
    "def get_unique_words(corpus):\n",
    "\treturn list(set(process_text(corpus)))\n",
    "\n",
    "def w2id_id2w_maps(unique_words):\n",
    "\t\"\"\" return both dictonaries for mapping between words and ids \"\"\"\n",
    "\tid2w = {i:w for i,w in enumerate(unique_words)}\n",
    "\tw2id = {w:i for i,w in id2w.items()}\n",
    "\treturn w2id, id2w\n",
    "\n",
    "def ngram_inc_amt(n):\n",
    "\t\"\"\" return float for increment weight of pair occurence n distance appart. \\nWeight increment ~ 1/n \"\"\"\n",
    "\treturn 1/float(n**2)\n",
    "\n",
    "def words2ids(words, w2id):\n",
    "\t\"\"\" return list of ids inplace of list of words using w2id dictionary \"\"\"\n",
    "\treturn [w2id[w] for w in words]\n",
    "\n",
    "def cooccurence_pair_of_distance(sentence_list, d):\n",
    "    \"\"\" return list of unique coocurence pairs of distace d \"\"\"\n",
    "\n",
    "    all_ngrams = ngrams(sentence_list,d)\n",
    "\n",
    "    all_pairs = []\n",
    "    for t in all_ngrams:\n",
    "        if len(t) > 1:\n",
    "            all_pairs.extend(list(itertools.combinations(t, 2)))\n",
    "\n",
    "    return list(set(all_pairs))\n",
    "\n",
    "def break_corpus(corpus):\n",
    "    \"\"\" Build Cooccurence Matrix. Return A, n, w2id, id2w \"\"\"\n",
    "\n",
    "    unique_words = get_unique_words(corpus)\n",
    "    n = len(unique_words)\n",
    "    w2id, id2w = w2id_id2w_maps(unique_words)\n",
    "\n",
    "    #create empty cooccurence matrix\n",
    "    #A = np.zeros([n,n],np.float32)\n",
    "    A = np.ones([n,n],np.float32)\n",
    "\n",
    "    #compute cooccurence matrix\n",
    "    sentences = sent_tokenize(corpus)\n",
    "    for s in sentences:\n",
    "        s = process_text(s)\n",
    "        max_distance = len(s) + 1\n",
    "        s = [w2id[w] for w in s]\t#convert words to ids\n",
    "\n",
    "        for d in range(2,max_distance):\n",
    "            pairs = cooccurence_pair_of_distance(s, d)\n",
    "\n",
    "            #update cooccurence matrix for each pair\n",
    "            for p in pairs:\n",
    "                A[p[0],p[1]] += ngram_inc_amt(d)\n",
    "                A[p[1],p[0]] += ngram_inc_amt(d)\n",
    "\n",
    "    return A, n, w2id, id2w\n",
    "\n",
    "A, n, w2id, id2w = break_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa', 'bb', 'gg', 'ff', 'cc', 'dd', 'ee']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rank_most_related_words(A, w2id, id2w, w1):\n",
    "    col = A[:,w2id[w1]].tolist()\n",
    "\n",
    "    list_of_index_value_tuples = list(zip(list(range(len(col))),col))\n",
    "    #(colindex,value)\n",
    "    sorted_indexs_value_tuples = sorted(list_of_index_value_tuples, key=lambda x: x[1])\n",
    "    sorted_indexs_value_tuples.reverse()\n",
    "    indexs, values = zip(*sorted_indexs_value_tuples)\n",
    "    ranked_words = [id2w[i] for i in indexs]\n",
    "    return ranked_words\n",
    "\n",
    "rank_most_related_words(A,w2id, id2w, 'aa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#internal\n",
    "import random\n",
    "\n",
    "#external\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "Matrix Decomposition\n",
    "\tMethod 1) Singular Value Decomposition of Forced Square Symmetric Positive Definite Matrix\n",
    "\tMethod 2) Eigen Decomposition of Forced Square Symmetric Positive Matrix\n",
    "\tMethod 3) Stocastic Gradient Decent Decomposition\n",
    "\"\"\"\n",
    "\n",
    "# check symmetry of matrix up to some tolerance\n",
    "def check_symmetric(a, tol=1e-8):\n",
    "    return np.allclose(a, a.T, atol=tol)\n",
    "\n",
    "#force square symetric matrix to symetric positive definite matrix\n",
    "def to_positive_definite(S):\n",
    "    \"\"\" Take absolute value of S and update diagnol entries to make a diagonally dominant matrix with diagonal entries greater than 0. \"\"\"\n",
    "    # take absolute value of S\n",
    "    S = np.absolute(S)\n",
    "\n",
    "    # Sum rows in S\n",
    "    new_diagonals = S.sum(axis=1)\n",
    "\n",
    "    #replace diagnols in S\n",
    "    np.fill_diagonal(S, new_diagonals)\n",
    "\n",
    "    return S\n",
    "\n",
    "\"\"\"\n",
    "####################################################################################\n",
    "# Singular Value Decomposition of Forced Square Symmetric Positive Definite Matrix #\n",
    "####################################################################################\n",
    "1.) Force Cooccurence Matrix A to Positive Definite Matrix\n",
    "    \" A diagonally dominant(by rows) symetric matrix with diagonal elements all greater than zero is positive definite.\"\n",
    "    Take symmetric matrix and make diagonally dominant with diagnonal entries greater than 0\n",
    "2.) Square Symmetric Positive Definite Matrix Decomposition\n",
    "    \" If A is positive definite, then A = QLQt = UDV (where U=V=Q and L=D) can be written as A = WWt where W = Qsqrt(L) \"\n",
    "    -SVD: A=UDV, W = Vsqrt(diagnol(D))\n",
    "    Find V and D from singular value decomposition of A\n",
    "    return W = Vsqrt(D)\n",
    "overview of code:\n",
    "    #\n",
    "    # force symmetric matrix to positive definite matrix\n",
    "    #\n",
    "    # take absolute value of A\n",
    "    A = np.absolute(A)\n",
    "    # Sum rows in a\n",
    "    new_diagonals = A.sum(axis=1)\n",
    "    #replace diagnols in A\n",
    "    np.fill_diagonal(A, new_diagonals)\n",
    "    #\n",
    "    # decompose positive definite matrix\n",
    "    #\n",
    "    # singular value decomposition\n",
    "    U, D, V = np.linalg.svd(A, full_matrices=False)\n",
    "    #\n",
    "    # compute W from V and D of singular value decomposition\n",
    "    #\n",
    "    # Create matrix W = Vtsqrt(diagnol(D)) #why Vt?\n",
    "    W = np.dot(np.transpose(V), np.sqrt(np.diag(D)))\n",
    "    #A = WWt\n",
    "\"\"\"\n",
    "\n",
    "def svd_spd_decomposition(P):\n",
    "    \"\"\" return M such that P = MMt, where matrix parameter P is SPD \"\"\"\n",
    "    # Assert Matrix P is symetric\n",
    "    assert check_symmetric(P)\n",
    "\n",
    "    # singular value decomposition\n",
    "    U, D, V = np.linalg.svd(P, full_matrices=False)\n",
    "\n",
    "    # Create matrix W = Vtsqrt(diagnol(D)) #why Vt?\n",
    "    M = np.dot(np.transpose(V), np.sqrt(np.diag(D)))\n",
    "\n",
    "    return M\n",
    "\n",
    "def spd_decomposition(S):\n",
    "\t\"\"\" Force Cooccurence Matrix A to Positive Definite Matrix and decompose into W such that A = WWt. \"\"\"\n",
    "\tP = to_positive_definite(S)\n",
    "\tM = svd_spd_decomposition(P)\n",
    "\treturn M\n",
    "\n",
    "#\n",
    "# Perform Symmetric Positive Definite Decomposition\n",
    "#\n",
    "\n",
    "W = spd_decomposition(A)\n",
    "\n",
    "print(\"\\n\\n\\nSymmetric Positive Definite Decomposition:\\n\")\n",
    "print(\"\\n\\nA:\")\n",
    "print (A)\n",
    "print(\"\\n\\nA2 (modified into SPD):\\n\")\n",
    "print(to_positive_definite(A))\n",
    "print(\"\\nWWt:\\n\")\n",
    "print(np.dot(W, np.transpose(W)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
